{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe7191f0",
   "metadata": {},
   "source": [
    "Autor: Anderson Morillo Diaz\n",
    "\n",
    "Departamento de ingeniería de sistemas, Universidad tecnológica de Bolívar, Parque Industrial y Tecnológico Carlos Vélez Pombo Km 1 Vía Turbaco, Cartagena, Colombia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c09605",
   "metadata": {},
   "source": [
    "# Content\n",
    "- 1 Python Libraries\n",
    "\n",
    "- 2 Data Content\n",
    "\n",
    "- 3 Read and Analyse Data\n",
    "\n",
    "- 4 Dependent Variable Analysis\n",
    "\n",
    "- 5 Correlation Between Features\n",
    "\n",
    "- 6 Distribution of Features\n",
    "\n",
    "- 7 Preprocessing: Missing Value Problem\n",
    "\n",
    "- 8 Preprocessing: Train-Test Split and Normalization\n",
    "\n",
    "- 9 Modelling: comparing models\n",
    "\n",
    "- 10 Metrics Accuracy, Precision, Recall, F1, MSE\n",
    "\n",
    "- 11 Nonparametric statistics\n",
    "\n",
    "- 12 Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca44820c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c158acc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "## For Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import Counter\n",
    "####################\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "## Machine Learning Algorithm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "## To evaluate models\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from scikitplot.metrics import plot_roc\n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = pd.read_csv('D:/Anderson/Downloads/data/train_diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f06fba",
   "metadata": {},
   "source": [
    "# DATA CONTENT\n",
    "\n",
    "Columns Description:\n",
    "\n",
    "numero ID de la persona\n",
    "\n",
    "Number of times pregnant\n",
    "\n",
    "Plasma glucose concentration 2 hours in an oral glucose tolerance test\n",
    "\n",
    "Diastolic blood pressure (mm Hg)\n",
    "\n",
    "Triceps skin fold thickness (mm)\n",
    "\n",
    "2-Hour serum insulin (mu U/ml)\n",
    "\n",
    "Body mass index (weight in kg/(height in m)^2)\n",
    "\n",
    "Diabetes pedigree function\n",
    "\n",
    "Age (years)\n",
    "\n",
    "Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se elimina la columna p_id dado que esta solo representa la identificación el participante\n",
    "data = data.drop(columns=['p_id'])\n",
    "rows, columns = data.shape\n",
    "print('Rows--> ', rows)\n",
    "print('Columns--> ', columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97034ada",
   "metadata": {},
   "source": [
    "DATA ANALISIS\n",
    "Como estan compuesto el data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9013d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f78f75",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d362368b",
   "metadata": {},
   "source": [
    "por la naturaleza de los datos \"glucose_concentration\", \"blood_pressure\", \"skin_fold_thickness\", \"serum_insulin\", \"bmi\" estos no pueden ser 0 dado que sería un valor atípico y sin sentido, excepto que se presente dado para remplazar todas datos nulos en la toma de datos, por lo cual se toman como nulos para luego igualarlos a la nueva media presentada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a7bb3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NaN values of 0 for Glucose, Blood Pressure, Skin Thickness, Insulin, BMI\n",
    "cols = [\"glucose_concentration\", \"blood_pressure\", \"skin_fold_thickness\", \"serum_insulin\", \"bmi\"]\n",
    "for col in cols:\n",
    "    data[col].replace(0,np.NaN,inplace=True)\n",
    "\n",
    "# now we can see missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74aa7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c42893",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cambiar los datos nulos con las medias de los valores\n",
    "data = data.apply(lambda x: x.fillna(x.mean()), axis=0)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf53910",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(data[\"diabetes\"].value_counts())\n",
    "fig = px.pie(d, values = \"diabetes\", names = [\"no diabetes\", \"diabetes\"], hole = 0.35, opacity = 0.8,\n",
    "            labels = {\"label\" :\"diabetes\",\"diabetes\":\"Number of Samples\"})\n",
    "fig.update_layout(title = dict(text = \"Pie Chart of Potability Feature\"))\n",
    "fig.update_traces(textposition = \"outside\", textinfo = \"percent+label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9995f335",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dependent Variable Analaysis:\n",
    "\n",
    "probar la depencia de las varaibles y si cumplen con los requisitos de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5457e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap(data.corr(), cmap = \"vlag\", dendrogram_ratio = (0.1, 0.2), annot = True, linewidths = .8, figsize = (9,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340813e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "non_diabetes = data.query(\"diabetes == 0\")\n",
    "diabetes = data.query(\"diabetes == 1\")\n",
    "\n",
    "plt.figure(figsize = (15,15))\n",
    "for ax, col in enumerate(data.columns[:9]):\n",
    "    plt.subplot(3,3, ax + 1)\n",
    "    plt.title(col)\n",
    "    sns.kdeplot(x = non_diabetes[col], label = \"No diabetes\")\n",
    "    sns.kdeplot(x = diabetes[col], label = \"diabetes\")\n",
    "    plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac7348c",
   "metadata": {},
   "source": [
    "Los datos presenta una correlación debil con los resultados de las diabetes, pero estos presentan una distribución normal a simple vista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72199bac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954bd1cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target = data['diabetes']\n",
    "data.drop(columns='diabetes', axis=1, inplace=True)\n",
    "\n",
    "scale = StandardScaler()\n",
    "newData = pd.DataFrame(scale.fit_transform(data), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c49a2fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "newData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01185c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c93e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(newData, target, test_size=0.3, random_state=3)\n",
    "\n",
    "\n",
    "print(f\"Training target statistics: {Counter(y_train)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8afca5b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# min-max normalization\n",
    "x_train_max = np.max(X_train)\n",
    "x_train_min = np.min(X_train)\n",
    "X_train = (X_train - x_train_min)/(x_train_max-x_train_min)\n",
    "X_test = (X_test - x_train_min)/(x_train_max-x_train_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe68e2b",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8efda4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "models = [('LR', LogisticRegression()),\n",
    "          ('KNN', KNeighborsClassifier()),\n",
    "          ('CART', DecisionTreeClassifier()),\n",
    "          ('RF', RandomForestClassifier()),\n",
    "          ('GB',GradientBoostingClassifier()),\n",
    "          (\"LightGBM\", LGBMClassifier())]\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f std:(%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e0ab8",
   "metadata": {},
   "source": [
    "El modelos que presenta mejor comportamiento es la regresion logictica, presentando mayor presición con 0.7529 y una desviación estandar menor que todos los otros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe71ba5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "models = [('LR', LogisticRegression())]\n",
    "\n",
    "def build_and_test(X_tr, X_te, y_tr, y_te, class_weight=None, threshold=False):\n",
    "    # Build and fit the model\n",
    "    for name, model in models:\n",
    "            kfold = KFold(n_splits=10)\n",
    "            model.fit(X_tr, y_tr)\n",
    "\n",
    "            # Test the model\n",
    "            y_pred = model.predict(X_te)\n",
    "            print(f'Precision score {model} %s' % precision_score(y_te, y_pred))\n",
    "            print(f'Recall score {model} %s' % recall_score(y_te, y_pred))\n",
    "            print(f'F1-score score {model} %s' % f1_score(y_te, y_pred))\n",
    "            print(f'Accuracy score {model} %s' % accuracy_score(y_te, y_pred))\n",
    "\n",
    "            y_score = model.predict_proba(X_te)\n",
    "            fpr0, tpr0, thresholds = roc_curve(y_te, y_score[:, 1])\n",
    "            roc_auc0 = auc(fpr0, tpr0)\n",
    "\n",
    "            #Calculate the best threshold\n",
    "            best_threshold = None\n",
    "            if threshold:\n",
    "                J = tpr0 - fpr0\n",
    "                ix = argmax(J) # take the value which maximizes the J variable\n",
    "                best_threshold = thresholds[ix]\n",
    "                # adjust score according to threshold.\n",
    "                y_score = np.array([[1, y[1]] if y[0] >= best_threshold else [0, y[1]] for y in     y_score])\n",
    "\n",
    "\n",
    "            # Plot metrics\n",
    "            plot_roc(y_te, y_score)\n",
    "            plt.show()\n",
    "\n",
    "            # Print a classification report\n",
    "            print(classification_report(y_te,y_pred))\n",
    "    return roc_auc0,fpr0,tpr0, best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104eac0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Oversample the smallest class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab12cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejecutar para un dataset pequeño arreglar\n",
    "dt_test = pd.read_csv('D:/Anderson/Downloads/data/test_diabetes.csv')\n",
    "dt_test = dt_test.drop(columns=['p_id'])\n",
    "\n",
    "#target_t = dt_test['diabetes']\n",
    "#data.drop(columns='diabetes', axis=1, inplace=True)\n",
    "\n",
    "scale_t = StandardScaler()\n",
    "newData_t = pd.DataFrame(scale_t.fit_transform(dt_test), columns=dt_test.columns)\n",
    "\n",
    "\n",
    "\n",
    "'''model.fit(X_tr, y_tr)\n",
    "         # Test the model\n",
    "y_pred = model.predict(X_te)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d6be5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "over_sampler = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = over_sampler.fit_resample(X_train, y_train)\n",
    "print(f\"Training target statistics: {Counter(y_res)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6012d92a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "roc_auc_ros,fpr_ros,tpr_ros, _ = build_and_test(X_res, X_test, y_res, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersample the biggest dataset with random under sampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "under_sampler = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = under_sampler.fit_resample(X_train, y_train)\n",
    "print(f\"Training target statistics: {Counter(y_res)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_rus,fpr_rus,tpr_rus , _ = build_and_test(X_res, X_test, y_res, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc8e73",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Bibliografia:\n",
    "\n",
    "[1] ‘Documentaion scikit-learn’, https://scikit-learn.org/0.21/documentation.html, accessed 19 abril 2022\n",
    "\n",
    "[2] ‘DiabetesClassificationProject’, https://www.kaggle.com/code/alibabaei78/diabetesclassificationproject, accessed 19 abril 2022\n",
    "\n",
    "[3] ‘Diabetes Prediction Using Classification Models’, https://www.kaggle.com/code/simgeerek/diabetes-prediction-using-classification-models, accessed 19 abril 2022\n",
    "\n",
    "[4] ‘How to balance a dataset in Python’,https://towardsdatascience.com/how-to-balance-a-dataset-in-python-36dff9d12704#:~:text=A%20balanced%20dataset%20is%20a,class%20weight, accessed 19 abril 2022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}